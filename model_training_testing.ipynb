{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0d00178-dba7-49b9-9539-cd54c9083421",
   "metadata": {},
   "source": [
    "# Some References for Inspiration\n",
    "\n",
    "* [Real/Fake Job Posting Prediction](https://www.kaggle.com/datasets/shivamb/real-or-fake-fake-jobposting-prediction)\n",
    "* [Fine-tuing BERT model for text classification](https://www.kaggle.com/datasets/shivamb/real-or-fake-fake-jobposting-prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e46efec6-21a2-43aa-bd15-dfd569e83847",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166b5f89-1c08-436d-bc96-8812222abce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf3ea32-a048-44a2-8044-477a4f7eccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobPostingDataset(Dataset):    \n",
    "    def __init__(self, mode, data, label_column, tokenizer):\n",
    "        assert mode in [\"train\", \"test\"]\n",
    "        self.mode = mode        \n",
    "        self.df = copy.deepcopy(data).fillna(\"\")\n",
    "        self.len = len(self.df)\n",
    "        self.label_column = label_column\n",
    "        self.label_map = {label:index for index, label in enumerate(list(set(self.df[label_column].to_list())))}\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"test\":\n",
    "            text = self.df.iloc[idx, :1].values\n",
    "            label_tensor = None\n",
    "        else:\n",
    "            text, label = self.df.iloc[idx, :].values            \n",
    "            label_id = self.label_map[label]\n",
    "            label_tensor = torch.tensor(label_id)\n",
    "            \n",
    "        text_word_pieces = self.tokenizer.tokenize(text, max_length=512, truncation=True)\n",
    "        text_len = len(text_word_pieces)\n",
    "                \n",
    "        ids = self.tokenizer.convert_tokens_to_ids(text_word_pieces)\n",
    "        tokens_tensor = torch.tensor(ids)\n",
    "\n",
    "        segments_tensor = torch.tensor([0]*text_len, dtype=torch.long)\n",
    "        \n",
    "        return (tokens_tensor, segments_tensor, label_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "273bb233-9175-46c2-8436-e8c696ed9c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch(samples):\n",
    "    tokens_tensors = [s[0] for s in samples]\n",
    "    segments_tensors = [s[1] for s in samples]\n",
    "    \n",
    "    # 測試集有 labels\n",
    "    if samples[0][2] is not None:\n",
    "        label_ids = torch.stack([s[2] for s in samples])\n",
    "    else:\n",
    "        label_ids = None\n",
    "    \n",
    "    # zero pad 到同一序列長度\n",
    "    tokens_tensors = pad_sequence(tokens_tensors, \n",
    "                                  batch_first=True)\n",
    "    segments_tensors = pad_sequence(segments_tensors, \n",
    "                                    batch_first=True)\n",
    "    \n",
    "    # attention masks，將 tokens_tensors 裡頭不為 zero padding\n",
    "    # 的位置設為 1 讓 BERT 只關注這些位置的 tokens\n",
    "    masks_tensors = torch.zeros(tokens_tensors.shape, \n",
    "                                dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(\n",
    "        tokens_tensors != 0, 1)\n",
    "    \n",
    "    return tokens_tensors, segments_tensors, masks_tensors, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22d5b1f7-df1f-4e1e-8f7e-070c5f8fa9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader, compute_acc=False):\n",
    "    predictions = None\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    recall_total = 0\n",
    "    recall_correct = 0\n",
    "    precision_total = 0\n",
    "    precision_correct = 0\n",
    "      \n",
    "    with torch.no_grad():\n",
    "        # 遍巡整個資料集\n",
    "        for data in dataloader:\n",
    "            # 將所有 tensors 移到 GPU 上\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "            \n",
    "            \n",
    "            # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n",
    "            # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n",
    "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "            \n",
    "            outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors)\n",
    "            \n",
    "            logits = outputs[0]\n",
    "            _, pred = torch.max(logits.data, 1)\n",
    "            \n",
    "            # 用來計算訓練集的分類準確率\n",
    "            if compute_acc:\n",
    "                labels = data[3]\n",
    "                \n",
    "                total += labels.size(0)                \n",
    "                recall_total += (labels==1).sum().item()\n",
    "                precision_total += (pred==1).sum().item()\n",
    "                \n",
    "                correct += (pred==labels).sum().item()\n",
    "                recall_correct += ((pred==labels)&(labels==1)).sum().item()\n",
    "                precision_correct += ((pred==labels)&(pred==1)).sum().item()\n",
    "                \n",
    "            # 將當前 batch 記錄下來\n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "    \n",
    "    if compute_acc:\n",
    "        acc = correct / total\n",
    "        \n",
    "        recall = 0\n",
    "        if recall_total > 0:\n",
    "            recall = recall_correct/recall_total\n",
    "        \n",
    "        precision = 0\n",
    "        if precision_total > 0:\n",
    "            precision = precision_correct/precision_total\n",
    "        \n",
    "        return predictions, acc, recall, precision\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cfd3016-fcb2-4e1a-8b75-a29f7a95875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "TARGET_COLUMN = \"fraudulent\"\n",
    "BESED_MODEL = \"bert-base-cased\"\n",
    "NUM_CLASS = 2\n",
    "\n",
    "#\n",
    "BATCH_SIZE = 16\n",
    "TRAIN_RUNS = 10\n",
    "MAX_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "768382f7-a013-41c1-ac79-dced438d0c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(BESED_MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BESED_MODEL, num_labels=NUM_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14c21851-9807-4a6f-b769-c1aed6b67a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Part Time Administrative Assistant US NJ Elmwo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Back End Engineer Platform Team GB Lost My Nam...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr Accountant Financial Analyst US The positio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Social Universe Project Manager MX DIF Grandat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Junior Developer NL NH Amsterdam About the Com...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14299</th>\n",
       "      <td>Outside Sales Professional Kenosha US WI Kenos...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14300</th>\n",
       "      <td>Commercial Real Estate Salesperson NJ US NJ El...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14301</th>\n",
       "      <td>Sales Executive US CA Sacramento Dice is a hig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14302</th>\n",
       "      <td>Customer Experience Professionals US TX Austin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14303</th>\n",
       "      <td>Linux System Administrator DE BE Berlin DaWand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  fraudulent\n",
       "0      Part Time Administrative Assistant US NJ Elmwo...           0\n",
       "1      Back End Engineer Platform Team GB Lost My Nam...           0\n",
       "2      Sr Accountant Financial Analyst US The positio...           0\n",
       "3      Social Universe Project Manager MX DIF Grandat...           0\n",
       "4      Junior Developer NL NH Amsterdam About the Com...           0\n",
       "...                                                  ...         ...\n",
       "14299  Outside Sales Professional Kenosha US WI Kenos...           0\n",
       "14300  Commercial Real Estate Salesperson NJ US NJ El...           0\n",
       "14301  Sales Executive US CA Sacramento Dice is a hig...           0\n",
       "14302  Customer Experience Professionals US TX Austin...           0\n",
       "14303  Linux System Administrator DE BE Berlin DaWand...           0\n",
       "\n",
       "[14304 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"splitted_text_data/train.csv\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f81b6b1-0d5e-466d-b61c-5c45d67cb425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "[run 1][epoch 10] loss: 1.005, acc: 0.951, recall: 0.000, precision: 0.000000\n",
      "[run 2][epoch 9] loss: 0.250, acc: 1.000, recall: 1.000, precision: 1.000000\n",
      "[run 3][epoch 7] loss: 0.459, acc: 1.000, recall: 1.000, precision: 1.000000\n",
      "[run 4][epoch 7] loss: 0.166, acc: 1.000, recall: 1.000, precision: 1.000000\n",
      "[run 5][epoch 3] loss: 0.356, acc: 1.000, recall: 1.000, precision: 1.000000\n",
      "[run 6][epoch 9] loss: 0.123, acc: 1.000, recall: 1.000, precision: 1.000000\n",
      "[run 7][epoch 5] loss: 0.447, acc: 1.000, recall: 1.000, precision: 1.000000\n",
      "[run 8][epoch 3] loss: 0.211, acc: 1.000, recall: 1.000, precision: 1.000000\n",
      "[run 9][epoch 3] loss: 0.254, acc: 1.000, recall: 1.000, precision: 1.000000\n",
      "[run 10][epoch 5] loss: 0.295, acc: 1.000, recall: 1.000, precision: 1.000000\n",
      "CPU times: user 12min 14s, sys: 7min 6s, total: 19min 21s\n",
      "Wall time: 19min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 訓練模式\n",
    "model.train()\n",
    "\n",
    "# 使用 Adam Optim 更新整個分類模型的參數\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model = model.to(device)\n",
    "\n",
    "for run in range(TRAIN_RUNS):\n",
    "    \n",
    "    train_sample_dataset = JobPostingDataset(\"train\", data=train_df.sample(frac=0.01), label_column=TARGET_COLUMN, tokenizer=tokenizer)\n",
    "    train_sample_data_loader = DataLoader(train_sample_dataset, batch_size=BATCH_SIZE, collate_fn=mini_batch)\n",
    "    acc, recall, precision, eps, eps_loss = 0, 0, 0, 0, 0\n",
    "\n",
    "    for epoch in range(MAX_EPOCHS):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for data in train_sample_data_loader:\n",
    "\n",
    "            tokens_tensors, segments_tensors, masks_tensors, labels = [t.to(device) for t in data]\n",
    "\n",
    "            # 將參數梯度歸零\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors, \n",
    "                            labels=labels)\n",
    "\n",
    "            loss = outputs[0]\n",
    "            # backward\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            # 紀錄當前 batch loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # 計算分類準確率\n",
    "        _, acc, recall, precision = get_predictions(model, train_sample_data_loader, compute_acc=True)\n",
    "        eps, eps_loss = epoch, running_loss\n",
    "\n",
    "        if recall == 1 and precision == 1:            \n",
    "            break\n",
    "\n",
    "    print(\"[run %d][epoch %d] loss: %.3f, acc: %.3f, recall: %.3f, precision: %3f\" % (run+1, eps+1, eps_loss, acc, recall, precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deb2895a-6f1a-4afb-9128-bb48c9e14d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbe9e49-2d23-400f-8d3d-9984998d77a9",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "387909b7-9781-4784-bbff-3f01f4f53c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UX Front End Developer GR I Athens Nubis is at...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Production Manager Heavy Duty Diesel 2022 US T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Security System Installer 2GIG US DE Wilmingto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Talent Acquisition Specialist USA US NY New Yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Graduates English Teacher Abroad Conversationa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3571</th>\n",
       "      <td>Outside Sales Professional US East Peoria ABC ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3572</th>\n",
       "      <td>Head of Online Marketing DE BY Munich hello wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>English Teacher Abroad US NY Alfred We help te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>Sales Director Business to Business Channel US...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3575</th>\n",
       "      <td>SEO Consultant GB LND Camden London Forward3D ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3576 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  fraudulent\n",
       "0     UX Front End Developer GR I Athens Nubis is at...           0\n",
       "1     Production Manager Heavy Duty Diesel 2022 US T...           1\n",
       "2     Security System Installer 2GIG US DE Wilmingto...           0\n",
       "3     Talent Acquisition Specialist USA US NY New Yo...           0\n",
       "4     Graduates English Teacher Abroad Conversationa...           0\n",
       "...                                                 ...         ...\n",
       "3571  Outside Sales Professional US East Peoria ABC ...           0\n",
       "3572  Head of Online Marketing DE BY Munich hello wo...           0\n",
       "3573  English Teacher Abroad US NY Alfred We help te...           0\n",
       "3574  Sales Director Business to Business Channel US...           0\n",
       "3575  SEO Consultant GB LND Camden London Forward3D ...           0\n",
       "\n",
       "[3576 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"splitted_text_data/test.csv\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b417c250-9fe3-40e6-96b0-8c972139dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "test_dataset = JobPostingDataset(\"train\", data=test_df, label_column=TARGET_COLUMN, tokenizer=tokenizer)\n",
    "test_data_loader = DataLoader(train_sample_dataset, batch_size=BATCH_SIZE, collate_fn=mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4526191-2017-41f4-94ac-f0aed5cb36af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification acc:  0.986013986013986\n",
      "classification recall: 0.8571428571428571\n",
      "classification precision: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "_, acc, recall, precision = get_predictions(model, test_data_loader, compute_acc=True)\n",
    "print(\"classification acc: \", acc)\n",
    "print(\"classification recall:\", recall)\n",
    "print(\"classification precision:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc07b50-181f-496e-865b-a2ed098e7273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
